{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "34866d7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from timeit import Timer\n",
    "from collections import defaultdict\n",
    "import re\n",
    "np.random.seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2ae51207",
   "metadata": {},
   "outputs": [
    {
     "ename": "IndentationError",
     "evalue": "unexpected indent (Temp/ipykernel_24980/1593771623.py, line 5)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"C:\\Users\\wwwsi\\AppData\\Local\\Temp/ipykernel_24980/1593771623.py\"\u001b[1;36m, line \u001b[1;32m5\u001b[0m\n\u001b[1;33m    for n in range(len(sample_list)):\u001b[0m\n\u001b[1;37m    ^\u001b[0m\n\u001b[1;31mIndentationError\u001b[0m\u001b[1;31m:\u001b[0m unexpected indent\n"
     ]
    }
   ],
   "source": [
    "sample_list = [(1, 3, 5), (0, 1, 2), (1, 9, 8)]\n",
    "op = []\n",
    "for m in range(len(sample_list)):\n",
    "    li = [sample_list[m]]\n",
    "        for n in range(len(sample_list)):\n",
    "            if (sample_list[m][0] == sample_list[n][0] and\n",
    "                    sample_list[m][3] != sample_list[n][3]):\n",
    "                li.append(sample_list[n])\n",
    "        op.append(sorted(li, key=lambda dd: dd[3], reverse=True)[0])\n",
    "res = list(set(op))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c33c9133",
   "metadata": {},
   "source": [
    "## Concisely describe what task the code above accomplishes.\n",
    "From the constructed list, firstly, this sippnet selects one tupleand search the others in turn with the same first element and different last element, or only itself if none of others meets the requirement.\t<br/>\n",
    "Then it sorts the selected tuples/tuple by the last elements decending order and picks up the top one. Append that top one into the `op` list.\t<br/>\n",
    "Lastly, make the `op` list as a set, remove all the duplicate elements and turn it to a list again\n",
    "\n",
    "## Modifing for sippnet\n",
    "* The indentation before the second `for` loop is not appropriate\n",
    "```Python\n",
    "# Modified indentation\n",
    "    for n in range(len(sample_list)):\n",
    "        if (sample_list[m][0] == sample_list[n][0] and \\\n",
    "            sample_list[m][3] != sample_list[n][3]):\n",
    "        li.append(sample_list[n])\n",
    "    op.append(sorted(li, key=lambda dd: dd[3], reverse=True)[0])\n",
    "```\n",
    "* The 3 index of `sample_list[m][3] != sample_list[n][3]` is out of range.\n",
    "Since there are only three elements in a tuple, `(1,3,5)`for instance, the index ranges from 0 to 2. So that if the last element is needed, the code should be modified as `sample_list[m][2] != sample_list[n][2]`\n",
    "* The second for loop could start from `m+1` rather than `0` for more efficiency.\n",
    "\n",
    "## The modified snippet can be shown as below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25f2379d",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_list = [(1, 3, 5), (0, 1, 2), (1, 9, 8)]\n",
    "op = []\n",
    "for m in range(len(sample_list)):\n",
    "    li = [sample_list[m]] # [(1, 3, 5)], ...\n",
    "    for n in range(m+1, len(sample_list)):\n",
    "        if (sample_list[m][0] == sample_list[n][0] and \\\n",
    "                sample_list[m][2] != sample_list[n][2]):\n",
    "            li.append(sample_list[n])\n",
    "    op.append(sorted(li, key=lambda dd: dd[2], reverse=True)[0])\n",
    "res = list(set(op))\n",
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "71049533",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0, 1, 2), (1, 9, 8)]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_list = [(1, 3, 5), (0, 1, 2), (1, 9, 8)]\n",
    "op = []\n",
    "for m in range(len(sample_list)):\n",
    "    li = [sample_list[m]] # [(1, 3, 5)], ...\n",
    "    for n in range(m+1, len(sample_list)):\n",
    "        if (sample_list[m][0] == sample_list[n][0] and \\\n",
    "                sample_list[m][2] != sample_list[n][2]):\n",
    "            li.append(sample_list[n])\n",
    "    op.append(sorted(li, key=lambda dd: dd[2], reverse=True)[0])\n",
    "res = list(set(op))\n",
    "res"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55481892",
   "metadata": {},
   "source": [
    "## Question 1 - List of Tuples\n",
    "\n",
    "Write a function that uses NumPy and a list comprehension to generate a random list of `n` k-tuples containing integers ranging from `low` to `high`. Choose an appropriate name for your function, and reasonable default values for `k`, `low`, and `high`.\n",
    "\n",
    "Use `assert` to test that your function returns a list of tuples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "65565c30",
   "metadata": {},
   "outputs": [],
   "source": [
    "# every tuple in the list is random generated from low to high and is sorted.\n",
    "def list_of_tuples(n, k, low, high):\n",
    "    size = k\n",
    "    tup_list = []\n",
    "    for i in range(n):\n",
    "        tup = tuple(np.sort(np.random.randint(low, high, size)))\n",
    "        tup_list.append(tup)\n",
    "    return tup_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3353be08",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(10, 12, 13, 13, 13, 14, 15, 15, 17, 19), (11, 11, 16, 16, 17, 17, 17, 18, 18, 18), (10, 10, 13, 13, 14, 15, 15, 18, 19, 19), (10, 11, 11, 12, 13, 13, 13, 13, 17, 18), (10, 10, 12, 12, 13, 14, 17, 17, 19, 19)]\n"
     ]
    }
   ],
   "source": [
    "low = 10\n",
    "high = 20\n",
    "n = 5 # number of tuples\n",
    "k = 10 # number of elements for each tuple\n",
    "tup_list = list_of_tuples(n, k, low, high)\n",
    "print(tup_list)\n",
    "\n",
    "assert type(tup_list) == list\n",
    "for i in range(len(tup_list)):\n",
    "    assert type(tup_list[i]) == tuple"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "461acb15",
   "metadata": {},
   "source": [
    "## Question 2 - Refactor the Snippet [40 points]\n",
    "In this question, you will write functions to accomplish the goal you concisely described in part “a” of the warm up.\n",
    "\n",
    "a. Encapsulate the code snippet from the warmup into a function that parameterizes the role of 0 and 3 and is otherwise unchanged. Choose appropriate names for these paramters.\n",
    "\n",
    "b. Write an improved version of the function form part a that implements the suggestions from the code review you wrote in part b of the warmup.\n",
    "\n",
    "c. Write a function from scratch to accomplish the same task as the previous two parts. Your solution should traverse the input list of tuples no more than twice. Hint: consider using a dictionary or a default dictionary in your solution.\n",
    "\n",
    "d. Use the function you wrote in question 1 to generate a list of tuples as input(s), run and summarize a small Monte Carlo study comparing the execution times of the three functions above (a-c)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "68b25155",
   "metadata": {},
   "outputs": [],
   "source": [
    "# a)\n",
    "def sort_list(sample_list, same_idx, diff_idx, sort_idx):\n",
    "    # same_idx for the index of required same value \n",
    "    # diff_idx for the index of required different value  \n",
    "    # sort_idx for the sorting reference index\n",
    "    # sample_list = [(1, 3, 5), (0, 1, 2), (1, 9, 8)]\n",
    "    op = []\n",
    "    for m in range(len(sample_list)):\n",
    "        li = [sample_list[m]]\n",
    "        for n in range(len(sample_list)):\n",
    "            if (sample_list[m][same_idx] == sample_list[n][same_idx] and\n",
    "                    sample_list[m][diff_idx] != sample_list[n][diff_idx]):\n",
    "                li.append(sample_list[n])\n",
    "        op.append(sorted(li, key=lambda dd: dd[sort_idx], reverse=True)[0])\n",
    "    res = list(set(op))\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "70af3f3a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(10, 11, 11, 12, 13, 13, 13, 13, 17, 18), (11, 11, 16, 16, 17, 17, 17, 18, 18, 18), (10, 12, 13, 13, 13, 14, 15, 15, 17, 19)]\n"
     ]
    }
   ],
   "source": [
    "sample_list = tup_list\n",
    "same_idx = 0\n",
    "diff_idx = 2\n",
    "sort_idx = 1\n",
    "result = sort_list(sample_list, same_idx, diff_idx, sort_idx)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b1edffdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# b)\n",
    "def sort_list_modified(sample_list, same_idx, diff_idx, sort_idx):\n",
    "    # same_idx for the index of required same value \n",
    "    # diff_idx for the index of required different value  \n",
    "    # sort_idx for the sorting reference index\n",
    "    # sample_list = [(1, 3, 5), (0, 1, 2), (1, 9, 8)]\n",
    "    op = []\n",
    "    for m in range(len(sample_list)):\n",
    "        li = [sample_list[m]]\n",
    "        for n in range(m+1, len(sample_list)):\n",
    "            if (sample_list[m][same_idx] == sample_list[n][same_idx] and \\\n",
    "                    sample_list[m][diff_idx] != sample_list[n][diff_idx]):\n",
    "                li.append(sample_list[n])\n",
    "        op.append(sorted(li, key=lambda dd: dd[sort_idx], reverse=True)[0])\n",
    "    return list(set(op))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ee08b716",
   "metadata": {},
   "outputs": [],
   "source": [
    "# c)\n",
    "def sort_list_df(sample_list, same_idx, diff_idx, sort_idx):\n",
    "    # same_idx for the index of required same value \n",
    "    # diff_idx for the index of required different value  \n",
    "    # sort_idx for the sorting reference index\n",
    "    # sample_list = [(1, 3, 5), (0, 1, 2), (1, 9, 8)]\n",
    "    sample_df = pd.DataFrame(sample_list)\n",
    "    op = pd.DataFrame(columns=range(len(sample_list[0])))\n",
    "\n",
    "    for idx in range( len(sample_df) ):\n",
    "        same_col = sample_df[same_idx]\n",
    "        diff_col = sample_df[diff_idx]\n",
    "        select_index = [idx]\n",
    "        for idx_2 in range(idx+1, len(sample_df)):\n",
    "            if same_col[idx] == same_col[idx_2] and \\\n",
    "            diff_col[idx] != diff_col[idx_2]:\n",
    "                select_index.append(idx_2)\n",
    "        select_rows = sample_df.loc[select_index,:] # select rows meets the criteria\n",
    "        sr = select_rows.sort_values(by=sort_idx, ascending=False).iloc[[0],:]  # sort rows by selected column value\n",
    "        op = pd.concat([op, sr], ignore_index=True)\n",
    "    return op.drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "940f331c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# c_002\n",
    "def sort_list_df_2(sample_list, same_idx, diff_idx, sort_idx):\n",
    "    # same_idx for the index of required same value \n",
    "    # diff_idx for the index of required different value  \n",
    "    # sort_idx for the sorting reference index\n",
    "    # sample_list = [(1, 3, 5), (0, 1, 2), (1, 9, 8)]\n",
    "    sample_df = pd.DataFrame(sample_list)\n",
    "    op = pd.DataFrame(columns=range(len(sample_list[0])))\n",
    "    \n",
    "    same_idx_val = sample_df[same_idx]\n",
    "    same_value = same_idx_val.drop_duplicates().values # find the set of values on same_index col.\n",
    "    for val in same_value:\n",
    "        rows_same_idx = sample_df[sample_df[same_idx]==val]\n",
    "        # ignore the rows have same value on diff_idx\n",
    "        rows_diff_index = rows_same_idx.drop_duplicates(subset=[diff_idx])\n",
    "        sr = rows_diff_index.sort_values(by=sort_idx, ascending=False).iloc[[0],:]\n",
    "        op = pd.concat([op, sr], ignore_index=True)\n",
    "    return op.drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5ab54435",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Function</th>\n",
       "      <th>min, s</th>\n",
       "      <th>median, s</th>\n",
       "      <th>mean, s</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>sort_list</td>\n",
       "      <td>0.808224</td>\n",
       "      <td>0.815852</td>\n",
       "      <td>0.816855</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>sort_list_modified</td>\n",
       "      <td>0.424283</td>\n",
       "      <td>0.431029</td>\n",
       "      <td>0.435815</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>sort_list_df_2</td>\n",
       "      <td>0.309270</td>\n",
       "      <td>0.320283</td>\n",
       "      <td>0.318610</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Function    min, s median, s   mean, s\n",
       "0           sort_list  0.808224  0.815852  0.816855\n",
       "1  sort_list_modified  0.424283  0.431029  0.435815\n",
       "2      sort_list_df_2  0.309270  0.320283  0.318610"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# d)\n",
    "low = 5\n",
    "high = 50\n",
    "n = 500\n",
    "k = 100\n",
    "sample_list = list_of_tuples(n, k, low, high)\n",
    "\n",
    "same_idx = 0\n",
    "diff_idx = 2\n",
    "sort_idx = 1\n",
    "\n",
    "# timing with ndarray input: -------------------------------------------------\n",
    "time_nda = defaultdict(list)\n",
    "\n",
    "for f in [sort_list, sort_list_modified, sort_list_df_2]:\n",
    "    \n",
    "    tm_list = []\n",
    "\n",
    "    t = Timer('f(sample_list, same_idx, diff_idx, sort_idx)', globals={'f': f, 'sample_list': sample_list, \\\n",
    "                                                                       'same_idx': same_idx, 'diff_idx': diff_idx, 'sort_idx': sort_idx})\n",
    "    tm = t.repeat(repeat=3, number=10)\n",
    "\n",
    "    time_nda['Function'].append(f.__name__)\n",
    "    time_nda['min, s'].append(np.min(tm))\n",
    "    time_nda['median, s'].append(np.median(tm))\n",
    "    time_nda['mean, s'].append(np.mean(tm))\n",
    "\n",
    "time_nda = pd.DataFrame(time_nda)\n",
    "for c, d in zip(time_nda.columns, time_nda.dtypes):\n",
    "    if d == np.dtype('float64'):\n",
    "        time_nda[c] = time_nda[c].map(lambda x: '%5.6f' % x)\n",
    "time_nda"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78b3a6e5",
   "metadata": {},
   "source": [
    "## Question 3 - [30 points]\n",
    "\n",
    "In this question you will use Pandas to read, clean, and append several data files from the National Health and Nutrition Examination Survey NHANES. We will use the data you prepare in this question as the starting point for analyses in one or more future problem sets. For this problem, you should use the four cohorts spanning the years 2011-2018. You can find links to different NHANES cohorts here.\n",
    "\n",
    "* Use Python and Pandas to read and append the **demographic datasets** keeping only columns containing the **unique ids (SEQN), age (RIDAGEYR), race and ethnicity (RIDRETH3), education (DMDEDUC2), and marital status (DMDMARTL)**, along with the following variables related to the survey weighting: **(RIDSTATR, SDMVPSU, SDMVSTRA, WTMEC2YR, WTINT2YR)**. \n",
    "* Add an additional column identifying to which cohort each case belongs. Rename the columns with literate variable names using all lower case and convert each column to an appropriate type. Finally, save the resulting data frame to a serialized “round-trip” format of your choosing (e.g. pickle, feather, or parquet).\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "aa1cb936",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ================\n",
    "# a)\n",
    "demo_1112_df = pd.read_sas(\"https://wwwn.cdc.gov/Nchs/Nhanes/2011-2012/DEMO_G.XPT\")\n",
    "demo_1314_df = pd.read_sas(\"https://wwwn.cdc.gov/Nchs/Nhanes/2013-2014/DEMO_H.XPT\")\n",
    "demo_1516_df = pd.read_sas(\"https://wwwn.cdc.gov/Nchs/Nhanes/2015-2016/DEMO_I.XPT\")\n",
    "demo_1718_df = pd.read_sas(\"https://wwwn.cdc.gov/Nchs/Nhanes/2017-2018/DEMO_J.XPT\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e077dcd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "demo_df_list = [demo_1112_df, demo_1314_df, demo_1516_df, demo_1718_df]\n",
    "cohort_list = ['1112', '1314', '1516', '1718']\n",
    "\n",
    "# create a block dataframe\n",
    "demo_comb_df = pd.DataFrame(columns = ('SEQN', 'RIDAGEYR', 'RIDRETH3', 'DMDEDUC2', 'DMDMARTL', \\\n",
    "                               'RIDSTATR', 'SDMVPSU', 'SDMVSTRA', 'WTMEC2YR', 'WTINT2YR'))\n",
    "\n",
    "for idx in range(len(demo_df_list)):\n",
    "    df = demo_df_list[idx]\n",
    "    df_select = df.loc[:,['SEQN', 'RIDAGEYR', 'RIDRETH3', 'DMDEDUC2', 'DMDMARTL', \\\n",
    "                               'RIDSTATR', 'SDMVPSU', 'SDMVSTRA', 'WTMEC2YR', 'WTINT2YR']]\n",
    "    df_select['cohort'] = cohort_list[idx] \n",
    "    \n",
    "    demo_comb_df = pd.concat([demo_comb_df, df_select], ignore_index=True) # concatenate each cohort\n",
    "\n",
    "demo_comb_df = demo_comb_df.rename(columns={'SEQN': 'unique_ids', 'RIDAGEYR':'age', 'RIDRETH3':'race_and_ethnicity', \\\n",
    "                        'DMDEDUC2':'education', 'DMDMARTL':'marital_status'})\n",
    "demo_comb_df= demo_comb_df.convert_dtypes() # Convert the DataFrame to use best possible dtypes.\n",
    "demo_comb_df.to_pickle(\"demo_comb_df.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "aae2080b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\wwwsi\\.conda\\envs\\stats507\\lib\\site-packages\\pandas\\io\\sas\\sas_xport.py:475: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead.  To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x] = v\n"
     ]
    }
   ],
   "source": [
    "# ================\n",
    "# b)\n",
    "oral_1112_df = pd.read_sas(\"https://wwwn.cdc.gov/Nchs/Nhanes/2011-2012/OHXDEN_G.XPT\")\n",
    "oral_1314_df = pd.read_sas(\"https://wwwn.cdc.gov/Nchs/Nhanes/2013-2014/OHXDEN_H.XPT\")\n",
    "oral_1516_df = pd.read_sas(\"https://wwwn.cdc.gov/Nchs/Nhanes/2015-2016/OHXDEN_I.XPT\")\n",
    "oral_1718_df = pd.read_sas(\"https://wwwn.cdc.gov/Nchs/Nhanes/2017-2018/OHXDEN_J.XPT\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a9c629ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "oral_df_list = [oral_1112_df, oral_1314_df, oral_1516_df, oral_1718_df]\n",
    "cohort_list = ['1112', '1314', '1516', '1718']\n",
    "\n",
    "# create a block dataframe\n",
    "TC_list = []\n",
    "dictionary = {}\n",
    "\n",
    "for col in oral_1112_df.columns:\n",
    "    if 'TC' in col:\n",
    "        TC_list.append(col)\n",
    "TC_list  # find all the column name has 'TC' and 'CTC'\n",
    "oral_comb_df = pd.DataFrame(columns = ['SEQN', 'OHDDESTS'] + TC_list )\n",
    "\n",
    "# concatenate four modified dataframes\n",
    "for idx in range(len(oral_df_list)):\n",
    "    df = oral_df_list[idx]\n",
    "    df_select = df.loc[:, ['SEQN' , 'OHDDESTS'] + TC_list] \n",
    "    df_select['cohort'] = cohort_list[idx] \n",
    "    oral_comb_df = pd.concat([oral_comb_df, df_select], ignore_index=True) # concatenate each cohort\n",
    "\n",
    "# Rename the columns with literate variable names\n",
    "for col in TC_list:\n",
    "    num_str = re.findall(\"\\d+\",col)[0]  # find the digit in string\n",
    "    if 'CTC' in col:\n",
    "        dictionary.update({col:\"coronal_cavities_\"+num_str})\n",
    "    else:\n",
    "        dictionary.update({col:\"tooth_counts_\"+num_str})\n",
    "oral_comb_df = oral_comb_df.rename(columns=dictionary)\n",
    "\n",
    "# Convert the DataFrame to use best possible dtypes.\n",
    "oral_comb_df= oral_comb_df.convert_dtypes() \n",
    "# Save the resulting data frame to picle\n",
    "oral_comb_df.to_pickle(\"oral_comb_df.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ec4302c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the number of cases in the demographic final dataframe is 39156\n",
      "the number of cases in the oral health and dentition data final dataframe is 35909\n"
     ]
    }
   ],
   "source": [
    "# ================\n",
    "# c) report the number of cases there are in the two datasets above.\n",
    "num_of_case_demo = len(demo_comb_df)\n",
    "num_of_case_oral = len(oral_comb_df)\n",
    "print(\"the number of cases in the demographic final dataframe is %d\"%(num_of_case_demo))\n",
    "print(\"the number of cases in the oral health and dentition data final dataframe is %d\"%(num_of_case_oral))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c53dd62",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e22aa23",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc25d8d5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "jupytext": {
   "encoding": "# -*- coding: utf-8 -*-",
   "formats": "ipynb,py:light"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
